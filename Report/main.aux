\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Formal Problem Statement}{3}{section.1.1}}
\newlabel{mixing_model}{{1.1}{3}{Formal Problem Statement\relax }{equation.1.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}A Linear Mixing Model}{3}{subsection.1.1.1}}
\newlabel{linear_mixing_model}{{1.2}{4}{A Linear Mixing Model\relax }{equation.1.1.2}{}}
\newlabel{linear_unmixing_model}{{1.3}{4}{A Linear Mixing Model\relax }{equation.1.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Overview}{4}{section.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Overview over the different approaches to blind source separation covered in this report.\relax }}{4}{table.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{overviewTable}{{1.1}{4}{Overview over the different approaches to blind source separation covered in this report.\relax \relax }{table.caption.3}{}}
\citation{pearson1901}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Principal Component Analysis}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Formal Statement}{6}{section.2.1}}
\newlabel{pca_lagrangian}{{2.1}{6}{Formal Statement\relax }{equation.2.1.1}{}}
\newlabel{pca_gradient}{{2.2}{6}{Formal Statement\relax }{equation.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Singular Value Decomposition}{6}{subsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \textsc  {Matlab} code for SVD.\relax }}{7}{figure.caption.4}}
\newlabel{svd_code}{{2.1}{7}{\textsc {Matlab} code for SVD.\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}PCA Application to Blind Source Separation}{7}{section.2.2}}
\newlabel{pca_bss}{{2.2}{7}{PCA Application to Blind Source Separation\relax }{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces PCA Source Separation.\relax }}{8}{figure.caption.5}}
\newlabel{pca_time_series}{{2.2}{8}{PCA Source Separation.\relax \relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Standardized data points vs eigenvectors.\relax }}{8}{figure.caption.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Standardized data projected onto eigenvectors.\relax }}{9}{figure.caption.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Independent Component Analysis}{10}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Limitations of the ICA Model}{10}{section.3.1}}
\newlabel{ICA_restrictions}{{3.1}{10}{Limitations of the ICA Model\relax }{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}ICA in the Linear Mixing Model}{11}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Equivalent Specifications of ICA}{11}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Derivation of ICA Log Likelihood Function}{11}{subsection.3.2.2}}
\newlabel{ml_ica}{{3.2.2}{11}{Derivation of ICA Log Likelihood Function\relax }{subsection.3.2.2}{}}
\newlabel{ica_loglikelihood}{{3.4}{11}{Derivation of ICA Log Likelihood Function\relax }{equation.3.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Derivation of Stochastic Gradient Descent for ICA}{11}{subsection.3.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Preprocessing}{11}{subsection.3.2.4}}
\newlabel{ica_preprocessing}{{3.2.4}{11}{Preprocessing\relax }{subsection.3.2.4}{}}
\newlabel{ica_listing}{{\caption@xref {ica_listing}{ on input line 360}}{12}{Derivation of Stochastic Gradient Descent for ICA\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textsc  {Matlab} code for ML ICA by stochastic block gradient descent.\relax }}{12}{figure.caption.8}}
\newlabel{mlica_code}{{3.1}{12}{\textsc {Matlab} code for ML ICA by stochastic block gradient descent.\relax \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}BSS by ICA}{12}{section.3.3}}
\newlabel{BSS_ICA}{{3.3}{12}{BSS by ICA\relax }{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Limitations and Comparison with PCA}{12}{section.3.4}}
\newlabel{ica_conclusions}{{3.4}{12}{Limitations and Comparison with PCA\relax }{section.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces ICA on a $2\times 2$ BSS problem. Note the ``sign reversal'' for the blue sine wave (cf. Section \ref  {ICA_restrictions}).\relax }}{13}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Separating a speech signal (top left) from background music (top right) by ICA. Here we also observe that the sign of the original speech signal is reversed in the bottom right recovered signal. \relax }}{13}{figure.caption.10}}
\citation{roweis}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Single Sensor Blind Source Separation}{14}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ssbss_chap}{{4}{14}{Single Sensor Blind Source Separation\relax }{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Time Frequency Signal Representation}{14}{section.4.1}}
\newlabel{timeFreqRep}{{4.1}{14}{Time Frequency Signal Representation\relax }{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}A Latent Variable Model for BSS}{15}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Generative Model and Estimation}{15}{subsection.4.2.1}}
\newlabel{maxvq_eqn}{{4.1}{15}{Generative Model and Estimation\relax }{equation.4.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Inference}{15}{subsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Spectrogram of male voice counting from one to ten.\relax }}{16}{figure.caption.11}}
\newlabel{bound}{{4.2}{16}{Inference\relax }{equation.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Factorial Hidden Markov Model for BSS}{16}{section.4.3}}
\newlabel{fhmm}{{4.3}{16}{Factorial Hidden Markov Model for BSS\relax }{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Initialization}{17}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Separation}{17}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Results}{18}{section.4.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{19}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Literature Review}{20}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Introduction}{20}{section.A.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Stationary linear mixing process and separation.\relax }}{21}{figure.caption.12}}
\newlabel{pca_time_series}{{A.1}{21}{Stationary linear mixing process and separation.\relax \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Literature Review Process}{21}{section.A.2}}
\newlabel{reviewProcess}{{A.2}{21}{Literature Review Process\relax }{section.A.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Magnitude of hits on the most general terms\relax }}{21}{table.caption.13}}
\newlabel{tab:myfirsttable}{{A.1}{21}{Magnitude of hits on the most general terms\relax \relax }{table.caption.13}{}}
\citation{comon94}
\citation{comon94}
\citation{bellSejnowski95}
\citation{pearlmutterParra}
\citation{fastICA}
\citation{hyvarinen2001}
\citation{mijovic2010}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Literature Overview}{23}{section.A.3}}
\newlabel{overview}{{A.3}{23}{Literature Overview\relax }{section.A.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Independent Component Analysis}{23}{subsection.A.3.1}}
\citation{bach}
\citation{VargaHMMDecomp}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}Hidden Markov Model Decomposition of Speech and Noise}{25}{subsection.A.3.2}}
\newlabel{vargasEqn1}{{A.2}{25}{Hidden Markov Model Decomposition of Speech and Noise\relax }{equation.A.3.2}{}}
\newlabel{vargasEqn2}{{A.3}{25}{Hidden Markov Model Decomposition of Speech and Noise\relax }{equation.A.3.3}{}}
\newlabel{vargasEqn3}{{A.4}{25}{Hidden Markov Model Decomposition of Speech and Noise\relax }{equation.A.3.4}{}}
\citation{roweisOneMic}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.3}Factoral Hidden Markov Models}{26}{subsection.A.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces Hidden Markov Model\relax }}{26}{figure.caption.15}}
\newlabel{hmm_figure}{{A.2}{26}{Hidden Markov Model\relax \relax }{figure.caption.15}{}}
\newlabel{roweisEqn1}{{A.5}{26}{Factoral Hidden Markov Models\relax }{equation.A.3.5}{}}
\newlabel{roweisEqn2}{{A.6}{26}{Factoral Hidden Markov Models\relax }{equation.A.3.6}{}}
\newlabel{roweisEqn3}{{A.7}{26}{Factoral Hidden Markov Models\relax }{equation.A.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces Factorial Hidden Markov Model\relax }}{27}{figure.caption.16}}
\newlabel{fhmm_figure}{{A.3}{27}{Factorial Hidden Markov Model\relax \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Conclusion}{27}{section.A.4}}
\newlabel{conclusion}{{A.4}{27}{Conclusion\relax }{section.A.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {.1}Research Agenda}{28}{section.Alph0.1}}
\newlabel{protocol}{{.1}{28}{Research Agenda\relax }{section.Alph0.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.1}Background}{28}{subsection.Alph0.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.2}Research Questions}{28}{subsection.Alph0.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.3}Search Strategy}{28}{subsection.Alph0.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{Databases}{29}{section*.17}}
\@writefile{toc}{\contentsline {subsubsection}{List of Search Terms}{29}{section*.18}}
\@writefile{toc}{\contentsline {subsubsection}{Inclusion and Quality Criteria}{29}{section*.19}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Mathematical Concepts}{30}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Linear Algebra}{30}{section.A.1}}
\@writefile{toc}{\contentsline {subsubsection}{The Eigenvector - Eigenvalue Problem}{30}{section*.20}}
\@writefile{toc}{\contentsline {subsubsection}{Singular Value Decomposition}{30}{section*.21}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Statistics and Optimization}{30}{section.A.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Maximum Likelihood Estimation}{31}{subsection.A.2.1}}
\newlabel{ml-estimation}{{A.2.1}{31}{Maximum Likelihood Estimation\relax }{subsection.A.2.1}{}}
\newlabel{ml-generic}{{A.1}{31}{Maximum Likelihood Estimation\relax }{equation.A.2.1}{}}
\newlabel{ml-iid}{{A.2}{31}{Maximum Likelihood Estimation\relax }{equation.A.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}Mathematical Optimization}{31}{subsection.A.2.2}}
\newlabel{optimization}{{A.2.2}{31}{Mathematical Optimization\relax }{subsection.A.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Lagrange Multiplier Method}{31}{section*.22}}
\@writefile{toc}{\contentsline {subsubsection}{Gradient Descent}{31}{section*.23}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Spectral Analysis}{31}{section.A.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Formal statement}{31}{subsection.A.3.1}}
\newlabel{stft}{{A.3}{32}{Formal statement\relax }{equation.A.3.3}{}}
\newlabel{spectrogram}{{A.4}{32}{Formal statement\relax }{equation.A.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Gaussian Mixture Models}{32}{section.A.4}}
\newlabel{gmm_appendix}{{A.4}{32}{Gaussian Mixture Models\relax }{section.A.4}{}}
\newlabel{gaussmix_eqn}{{A.5}{32}{Gaussian Mixture Models\relax }{equation.A.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.5}Hidden Markov Models}{32}{section.A.5}}
\newlabel{hmm_appendix}{{A.5}{32}{Hidden Markov Models\relax }{section.A.5}{}}
\newlabel{1st_order_markov}{{A.8}{33}{Hidden Markov Models\relax }{equation.A.5.8}{}}
\bibcite{comon94}{1}
\bibcite{bellSejnowski95}{2}
\bibcite{pearlmutterParra}{3}
\bibcite{hyvarinen2001}{4}
\bibcite{bach}{5}
\bibcite{fastICA}{6}
\bibcite{roweisOneMic}{7}
\bibcite{davies2007}{8}
\bibcite{cardoso98}{9}
\bibcite{mijovic2010}{10}
\bibcite{VargaHMMDecomp}{11}
\bibcite{pearson1901}{12}
\bibcite{norvig_russel}{13}
