\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\@writefile{@@@}{\chapterbegin }
\@writefile{@@@}{\chapterbegin }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Introduction}{5}{chapter.1}}
\@writefile{lot}{\contentsline {xchapter}{Introduction}{5}{chapter.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Formal Problem Statement}{6}{section.1.1}}
\newlabel{mixing_model}{{1.1}{6}{Formal Problem Statement\relax }{equation.1.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Single Sensor Blind Source Separation}{7}{subsection.1.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}A Linear Mixing Model}{7}{subsection.1.1.2}}
\newlabel{linear_mixing_model}{{1.2}{7}{A Linear Mixing Model\relax }{equation.1.1.2}{}}
\newlabel{linear_unmixing_model}{{1.3}{7}{A Linear Mixing Model\relax }{equation.1.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Overview}{8}{section.1.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Literature Review}{9}{chapter.2}}
\@writefile{lot}{\contentsline {xchapter}{Literature Review}{9}{chapter.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Stationary linear mixing process and separation.\relax }}{10}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{pca_time_series}{{2.1}{10}{Stationary linear mixing process and separation.\relax \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Review Protocol}{10}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Research Agenda}{10}{subsection.2.1.1}}
\newlabel{protocol}{{2.1.1}{10}{Research Agenda\relax }{subsection.2.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Background}{10}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Research Questions}{11}{subsection.2.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Search Strategy}{11}{subsection.2.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{Databases}{11}{section*.4}}
\@writefile{toc}{\contentsline {subsubsection}{List of Search Terms}{11}{section*.5}}
\citation{bellSejnowski95}
\citation{hyvarinen2001}
\@writefile{toc}{\contentsline {subsubsection}{Inclusion and Quality Criteria}{12}{section*.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Literature Review Process}{12}{section.2.2}}
\newlabel{reviewProcess}{{2.2}{12}{Literature Review Process\relax }{section.2.2}{}}
\citation{roweisOneMic}
\citation{VargaHMMDecomp}
\citation{comon94}
\citation{fastICA}
\citation{davies2007}
\citation{comon94}
\citation{comon94}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Magnitude of hits on the most general terms\relax }}{13}{table.caption.7}}
\newlabel{tab:myfirsttable}{{2.1}{13}{Magnitude of hits on the most general terms\relax \relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Literature Overview}{13}{section.2.3}}
\newlabel{overview}{{2.3}{13}{Literature Overview\relax }{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Independent Component Analysis}{13}{subsection.2.3.1}}
\citation{bellSejnowski95}
\citation{pearlmutterParra}
\citation{fastICA}
\citation{hyvarinen2001}
\citation{mijovic2010}
\citation{bach}
\citation{VargaHMMDecomp}
\citation{roweisOneMic}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Hidden Markov Model Decomposition of Speech and Noise}{15}{subsection.2.3.2}}
\newlabel{vargasEqn1}{{2.2}{15}{Hidden Markov Model Decomposition of Speech and Noise\relax }{equation.2.3.2}{}}
\newlabel{vargasEqn2}{{2.3}{15}{Hidden Markov Model Decomposition of Speech and Noise\relax }{equation.2.3.3}{}}
\newlabel{vargasEqn3}{{2.4}{15}{Hidden Markov Model Decomposition of Speech and Noise\relax }{equation.2.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Factoral Hidden Markov Models}{16}{subsection.2.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Hidden Markov Model\relax }}{16}{figure.caption.9}}
\newlabel{hmm_figure}{{2.2}{16}{Hidden Markov Model\relax \relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Factorial Hidden Markov Model\relax }}{17}{figure.caption.10}}
\newlabel{fhmm_figure}{{2.3}{17}{Factorial Hidden Markov Model\relax \relax }{figure.caption.10}{}}
\newlabel{roweisEqn1}{{2.5}{17}{Factoral Hidden Markov Models\relax }{equation.2.3.5}{}}
\newlabel{roweisEqn2}{{2.6}{17}{Factoral Hidden Markov Models\relax }{equation.2.3.6}{}}
\newlabel{roweisEqn3}{{2.7}{17}{Factoral Hidden Markov Models\relax }{equation.2.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Conclusion}{17}{section.2.4}}
\newlabel{conclusion}{{2.4}{17}{Conclusion\relax }{section.2.4}{}}
\citation{pearson1901}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Principal Component Analysis}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Principal Component Analysis}{19}{chapter.3}}
\@writefile{lot}{\contentsline {xchapter}{Principal Component Analysis}{19}{chapter.3}}
\newlabel{pca}{{3}{19}{Principal Component Analysis\relax }{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Intuition}{20}{section.3.1}}
\newlabel{pca_intuition}{{3.1}{20}{Intuition\relax }{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces After projecting the data onto the dark line, little variation left in the dataset.\relax }}{21}{figure.caption.11}}
\newlabel{pca1}{{3.1}{21}{After projecting the data onto the dark line, little variation left in the dataset.\relax \relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Projecting the data onto the dark line we reduce dimensionality while keeping a large portion of the variation characterizing the data.\relax }}{21}{figure.caption.12}}
\newlabel{pca2}{{3.2}{21}{Projecting the data onto the dark line we reduce dimensionality while keeping a large portion of the variation characterizing the data.\relax \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Formal Statement}{22}{section.3.2}}
\newlabel{pca_lagrangian}{{3.1}{22}{Formal Statement\relax }{equation.3.2.1}{}}
\newlabel{pca_gradient}{{3.2}{22}{Formal Statement\relax }{equation.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Singular Value Decomposition}{23}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}PCA Application to Blind Source Separation}{23}{section.3.3}}
\newlabel{pca_bss}{{3.3}{23}{PCA Application to Blind Source Separation\relax }{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces PCA Source Separation.\relax }}{24}{figure.caption.13}}
\newlabel{pca_time_series}{{3.3}{24}{PCA Source Separation.\relax \relax }{figure.caption.13}{}}
\newlabel{pca_eigs}{{\caption@xref {pca_eigs}{ on input line 842}}{25}{PCA Application to Blind Source Separation\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Standardized data points vs eigenvectors.\relax }}{25}{figure.caption.14}}
\newlabel{pca_project}{{\caption@xref {pca_project}{ on input line 850}}{25}{PCA Application to Blind Source Separation\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Standardized data projected onto eigenvectors.\relax }}{25}{figure.caption.15}}
\citation{Pham}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Independent Component Analysis}{26}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Independent Component Analysis}{26}{chapter.4}}
\@writefile{lot}{\contentsline {xchapter}{Independent Component Analysis}{26}{chapter.4}}
\newlabel{ica}{{4}{26}{Independent Component Analysis\relax }{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Equivalent Statements of ICA}{27}{section.4.1}}
\newlabel{equiv_ica}{{4.1}{27}{Equivalent Statements of ICA\relax }{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Kurtosis Maximization}{27}{subsection.4.1.1}}
\newlabel{kurtosis_eqn}{{4.3}{27}{Kurtosis Maximization\relax }{equation.4.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Minimum Mutual Information}{28}{subsection.4.1.2}}
\newlabel{determinant}{{4.7}{28}{Minimum Mutual Information\relax }{equation.4.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Limitations of the ICA Model}{28}{section.4.2}}
\newlabel{ICA_restrictions}{{4.2}{28}{Limitations of the ICA Model\relax }{section.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Maximum Likelihood ICA in the Linear Mixing Model}{29}{section.4.3}}
\newlabel{linear_model_ica}{{4.3}{29}{Maximum Likelihood ICA in the Linear Mixing Model\relax }{section.4.3}{}}
\newlabel{ica_prob}{{4.10}{30}{Maximum Likelihood ICA in the Linear Mixing Model\relax }{equation.4.3.10}{}}
\newlabel{max_likelihood}{{4.13}{30}{Maximum Likelihood ICA in the Linear Mixing Model\relax }{equation.4.3.13}{}}
\newlabel{bayes}{{4.14}{30}{Maximum Likelihood ICA in the Linear Mixing Model\relax }{equation.4.3.14}{}}
\newlabel{ica_loglikelihood}{{4.15}{30}{Maximum Likelihood ICA in the Linear Mixing Model\relax }{equation.4.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}A Gradient Descent Rule for ICA}{31}{subsection.4.3.1}}
\newlabel{gradient_descent}{{4.16}{31}{A Gradient Descent Rule for ICA\relax }{equation.4.3.16}{}}
\newlabel{ica_listing}{{\caption@xref {ica_listing}{ on input line 1144}}{31}{A Gradient Descent Rule for ICA\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Pseudocode for ML ICA by stochastic block gradient descent.\relax }}{31}{figure.caption.16}}
\newlabel{mlica_code}{{4.1}{31}{Pseudocode for ML ICA by stochastic block gradient descent.\relax \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}BSS by ICA}{32}{section.4.4}}
\newlabel{BSS_ICA}{{4.4}{32}{BSS by ICA\relax }{section.4.4}{}}
\newlabel{ica_fig1}{{\caption@xref {ica_fig1}{ on input line 1185}}{33}{BSS by ICA\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces ICA on a $2\times 2$ BSS problem. Note the ``sign reversal'' for the blue sine wave (cf. Section \ref  {ICA_restrictions}).\relax }}{33}{figure.caption.17}}
\newlabel{ica_fig2}{{\caption@xref {ica_fig2}{ on input line 1194}}{33}{BSS by ICA\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Separating a speech signal (top left) from background music (top right) by ICA. \relax }}{33}{figure.caption.18}}
\citation{roweis}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Single Sensor Blind Source Separation}{34}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Single Sensor Blind Source Separation}{34}{chapter.5}}
\@writefile{lot}{\contentsline {xchapter}{Single Sensor Blind Source Separation}{34}{chapter.5}}
\newlabel{ssbss_chap}{{5}{34}{Single Sensor Blind Source Separation\relax }{chapter.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Time domain representation of a male voice counting from one to ten.\relax }}{35}{figure.caption.19}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Time Frequency Signal Representation}{35}{section.5.1}}
\newlabel{timeFreqRep}{{5.1}{35}{Time Frequency Signal Representation\relax }{section.5.1}{}}
\newlabel{stft}{{5.1}{36}{Time Frequency Signal Representation\relax }{equation.5.1.1}{}}
\newlabel{spectrogram}{{5.2}{36}{Time Frequency Signal Representation\relax }{equation.5.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Log Max Approximation}{36}{section.5.2}}
\newlabel{logmaxapprox}{{5.2}{36}{Log Max Approximation\relax }{section.5.2}{}}
\newlabel{logmax_fig}{{\caption@xref {logmax_fig}{ on input line 1315}}{37}{Log Max Approximation\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Log-max approximation.\relax }}{37}{figure.caption.20}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Latent Variable BSS}{37}{section.5.3}}
\newlabel{latent_bss}{{5.3}{37}{Latent Variable BSS\relax }{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Gaussian Mixture Models}{37}{subsection.5.3.1}}
\newlabel{gmm_general}{{5.3.1}{37}{Gaussian Mixture Models\relax }{subsection.5.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces A mixture of gaussians distribution with two components.\relax }}{38}{figure.caption.21}}
\newlabel{gmm_fig}{{5.3}{38}{A mixture of gaussians distribution with two components.\relax \relax }{figure.caption.21}{}}
\newlabel{gaussmix_eqn}{{5.3}{38}{Gaussian Mixture Models\relax }{equation.5.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Generative Model}{39}{subsection.5.3.2}}
\newlabel{generative_model}{{5.3.2}{39}{Generative Model\relax }{subsection.5.3.2}{}}
\newlabel{maxvq_eqn}{{5.4}{39}{Generative Model\relax }{equation.5.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Estimation Procedure - The EM Algorithm}{39}{subsection.5.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}A Generic Inference Procedure}{40}{subsection.5.3.4}}
\newlabel{bayes_eqn1}{{5.7}{41}{A Generic Inference Procedure\relax }{equation.5.3.7}{}}
\newlabel{mahala}{{5.8}{41}{A Generic Inference Procedure\relax }{equation.5.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}An Improved Pruning Method for MAXVQ Inference}{41}{subsection.5.3.5}}
\newlabel{prune}{{5.3.5}{41}{An Improved Pruning Method for MAXVQ Inference\relax }{subsection.5.3.5}{}}
\newlabel{bound}{{5.9}{41}{An Improved Pruning Method for MAXVQ Inference\relax }{equation.5.3.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Factorial Hidden Markov Model for BSS}{42}{section.5.4}}
\newlabel{fhmm}{{5.4}{42}{Factorial Hidden Markov Model for BSS\relax }{section.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Hidden Markov Models}{42}{section.5.5}}
\newlabel{hmm_appendix}{{5.5}{42}{Hidden Markov Models\relax }{section.5.5}{}}
\newlabel{1st_order_markov}{{5.12}{42}{Hidden Markov Models\relax }{equation.5.5.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Pseudocode for MAXVQ algorithm.\relax }}{43}{figure.caption.22}}
\newlabel{maxvq_pseudo}{{5.4}{43}{Pseudocode for MAXVQ algorithm.\relax \relax }{figure.caption.22}{}}
\newlabel{count_spectrogram}{{\caption@xref {count_spectrogram}{ on input line 1654}}{44}{A HMM Blind Source Separation Framework\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Spectrogram of male voice counting from one to ten.\relax }}{44}{figure.caption.23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}A HMM Blind Source Separation Framework}{44}{subsection.5.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Initialization}{45}{subsection.5.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Separation}{45}{subsection.5.5.3}}
\newlabel{music_count}{{\caption@xref {music_count}{ on input line 1733}}{46}{Results\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Time domain plot of speech (top) and music (bottom).\relax }}{46}{figure.caption.24}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Results}{46}{section.5.6}}
\newlabel{ssbss_results}{{5.6}{46}{Results\relax }{section.5.6}{}}
\newlabel{spect_testset}{{\caption@xref {spect_testset}{ on input line 1752}}{47}{Results\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Spectrograms for test data.\relax }}{47}{figure.caption.25}}
\newlabel{voice_result}{{\caption@xref {voice_result}{ on input line 1780}}{48}{Results\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Spectrogram for recovered voice signal.\relax }}{48}{figure.caption.26}}
\newlabel{music_result}{{\caption@xref {music_result}{ on input line 1788}}{48}{Results\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Spectrogram for recovered music signal.\relax }}{48}{figure.caption.27}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Further Study}{50}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Conclusion and Further Study}{50}{chapter.6}}
\@writefile{lot}{\contentsline {xchapter}{Conclusion and Further Study}{50}{chapter.6}}
\bibcite{comon94}{1}
\bibcite{bellSejnowski95}{2}
\bibcite{pearlmutterParra}{3}
\bibcite{hyvarinen2001}{4}
\bibcite{bach}{5}
\bibcite{fastICA}{6}
\bibcite{roweisOneMic}{7}
\bibcite{davies2007}{8}
\bibcite{cardoso98}{9}
\bibcite{mijovic2010}{10}
\@writefile{@@@}{\chapterbegin }
\bibcite{VargaHMMDecomp}{11}
\bibcite{pearson1901}{12}
\bibcite{Pham}{13}
\bibcite{norvig_russel}{14}
\global\mtcsecondpartfalse
